{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales - 2019-2 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1  </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Manipulaciones en pandas y numpy, preprocesamientos\n",
    "* Redes Densas Feed Forward\n",
    "* Regularización y Dropout\n",
    "* Vanishing Gradient y Skip Connections\n",
    "* Learn Rate Decay\n",
    "* Optimizadores\n",
    "* Redes Convolucionales\n",
    "* Image Data Agumentation\n",
    "\n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de 2 personas (*Ambos estudiantes deben estar preparados para presentar la tarea el día de la entrega*)\n",
    "* El entregable debe ser un _Jupyter Notebook_ incluyendo los códigos utilizados, los resultados, los gráficos realizados y comentarios. Debe seguir una estructura similar a un informe (se debe introducir los problemas a trabajar, presentar los resultados y discutirlos), se penalizará fuertemente ausencia de comentarios, explicaciones de gráficos, _etc_. Si lo prefiere puede entregar un _Jupyter Notebook_ por pregunta o uno por toda la tarea, con tal de que todos los entregables esten bien identificados y se encuentren en el mismo repositorio de _Github_.\n",
    "* Se debe preparar una presentación del trabajo realizado y sus hallazgos. El presentador será elegido aleatoriamente y deberá apoyarse en el _Jupyter Notebook_ que entregarán. \n",
    "* Formato de entrega: envı́o de link del repositorio en _Github_, al correo electrónico del ayudante (<alvaro.valderrama.13@sansano.usm.cl>), en copia al profesor (<cvalle@inf.utfsm.cl>).   Especificar el siguiente asunto: [INF-395/477-2019 Tarea 1]. Invitar como colaborador al usuario de github \"avalderr\" para poder acceder al repositorio en caso de ser privado.\n",
    "* Fecha de entrega y presentaciones: 22 de Noviembre. Hora límite de entrega: 23:59. Cualquier _commit_ luego de la hora límite no será evaluado. Se realizará descuento por atrasos en envío del mail igualmente.  \n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en tres partes:\n",
    "\n",
    "* 1 - Redes Feed Forward para Airbnb\n",
    "* 2 - Reconocimiento de Imagenes en CIFAR10    \n",
    "* 3 - Reconocimiento de frutas y verduras\n",
    "\n",
    "La tarea tiene ejemplos de códigos con los cuales pueden guiarse en gran parte, sin embargo, solo son guias y pueden ser creativos al momento de resolver la tarea. Soluciones creativas o elegantes serán valoradas. También en algunas ocaciones se hacen elecciones arbitrarias, ustedes pueden realizar otras elecciones con tal de que haya una pequeña justificación de por qué su elección es mejor o equivalente.\n",
    "Recuerden intercalar su código con *comentarios* en celdas _Markdown_, con los comentarios de la pregunta y con cualquier analisis, fórmula (en $ \\LaTeX $) o explicación que les parezca relevante para justificar sus procedimientos. *No respondan las preguntas en comentarios en el código*.\n",
    "Noten que en general cuando se les pide elegir algo o proponer algo no se evaluará tanto la elección en si. En cambio la argumentación detrás de la elección será lo más ponderado.\n",
    "Si algun modelo se demora demasiado en correr en su maquina, no olvide que puede correr _Jupyter Notebooks_ en _Collab_ de Google, incluso con la opción de aceleración con GPU (particularmente útil para los modelos más grandes), esto puede ser relevante para las maquinas más lentas al momento de realizar exploraciones con _K-folds_ o las redes más grandes. Existe también la posibilidad de utilizar _Google Cloud Plataform_, donde tienen 300 dolares de prueba por un año y pueden comprar tiempo de procesamiento en maquinas aceleradas con GPU; maquinas ya configuradas para _deep leraning_ pueden encontrarse en el _Marketplace_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Redes Feed Forward para Airbnb\n",
    "\n",
    "De las redes neuronales artificiales más simples se encuentran las redes densas o _Feed Forward_, donde todas las neuronas de una capa estan conectadas a todos los inputs y envian su señal de activación a todas las neuronas de la siguiente capa. Estas redes, si bien son las más simples, suelen tener desempeños bastante buenos, y en muchas aplicaciones reales son utilizadas, ya sea por si solas o en combinación con otros modelos. Además, son las redes donde más facil se pueden observar muchos de los fenómenos que se han descubierto a lo largo de los años de desarrollo de esta area del conocimiento, tanto por ser de las redes vigentes más antiguas y por su estructura relativamente simple. En esta primera parte de la tarea exploraremos las redes densas y algunos de sus hiperparámetros más relevantes como la profundidad, el número de unidades; estudiaremos también algunos métodos de regularización y evidenciaremos el problema del _vanishing gradient_ y el _exploding gradient_, viendo también algunos optimizadores existentes. \n",
    "\n",
    "Para realizar esto, utilizaremos una base de datos de precios de inmuebles anunciados en Airbnb, la cual se encuentra disponible en _Kaggle_, en la siguiente URL: https://www.kaggle.com/stevezhenghp/airbnb-price-prediction. El dataset cuenta de casi mil registros, donde podemos encontrar el logaritmo del precio del anuncio, el tipo de propiedad, las amenidades disponibles, el número de personas que puede alojar, el número de baños, entre otros. \n",
    "Nuesta tarea durante esta pregunta será predecir el valor del logaritmo del precio del anuncio a partir de algunas de las otras variables presentes en el dataset. Para esto primero deberán preprocesar los datos para transformarlos a una forma que pueda ser utilizada por una red neuronal o eliminarlos en el caso que se estime conveniente. Una vez separados los datos de entrenamiento, validación y test, procederemos a entrenar diferentes modelos, comparandolos y evaluando sus desempeños. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a Carga de datos y primeros analisis\n",
    "Cargue los datos en un _dataframe_ como muestra el código. Explore superficialmente los datos utilizando los metodos `.head`, `.describe` o `.info` del _DataFrame_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6901257</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>{\"Wireless Internet\",\"Air conditioning\",Kitche...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>40.696524</td>\n",
       "      <td>-73.991617</td>\n",
       "      <td>Beautiful brownstone 1-bedroom</td>\n",
       "      <td>Brooklyn Heights</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/6d7cbbf7-c...</td>\n",
       "      <td>11201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6304928</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>{\"Wireless Internet\",\"Air conditioning\",Kitche...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>40.766115</td>\n",
       "      <td>-73.989040</td>\n",
       "      <td>Superb 3BR Apt Located Near Times Square</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/348a55fe-4...</td>\n",
       "      <td>10019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7919400</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>{TV,\"Cable TV\",\"Wireless Internet\",\"Air condit...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>40.808110</td>\n",
       "      <td>-73.943756</td>\n",
       "      <td>The Garden Oasis</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/6fae5362-9...</td>\n",
       "      <td>10027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13418779</td>\n",
       "      <td>6.620073</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,\"Wireless Internet\",Ki...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>37.772004</td>\n",
       "      <td>-122.431619</td>\n",
       "      <td>Beautiful Flat in the Heart of SF!</td>\n",
       "      <td>Lower Haight</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/72208dad-9...</td>\n",
       "      <td>94117.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3808709</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>{TV,Internet,\"Wireless Internet\",\"Air conditio...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>38.925627</td>\n",
       "      <td>-77.034596</td>\n",
       "      <td>Great studio in midtown DC</td>\n",
       "      <td>Columbia Heights</td>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  log_price property_type        room_type  \\\n",
       "0   6901257   5.010635     Apartment  Entire home/apt   \n",
       "1   6304928   5.129899     Apartment  Entire home/apt   \n",
       "2   7919400   4.976734     Apartment  Entire home/apt   \n",
       "3  13418779   6.620073         House  Entire home/apt   \n",
       "4   3808709   4.744932     Apartment  Entire home/apt   \n",
       "\n",
       "                                           amenities  accommodates  bathrooms  \\\n",
       "0  {\"Wireless Internet\",\"Air conditioning\",Kitche...             3        1.0   \n",
       "1  {\"Wireless Internet\",\"Air conditioning\",Kitche...             7        1.0   \n",
       "2  {TV,\"Cable TV\",\"Wireless Internet\",\"Air condit...             5        1.0   \n",
       "3  {TV,\"Cable TV\",Internet,\"Wireless Internet\",Ki...             4        1.0   \n",
       "4  {TV,Internet,\"Wireless Internet\",\"Air conditio...             2        1.0   \n",
       "\n",
       "   bed_type cancellation_policy  cleaning_fee  ...   latitude   longitude  \\\n",
       "0  Real Bed              strict          True  ...  40.696524  -73.991617   \n",
       "1  Real Bed              strict          True  ...  40.766115  -73.989040   \n",
       "2  Real Bed            moderate          True  ...  40.808110  -73.943756   \n",
       "3  Real Bed            flexible          True  ...  37.772004 -122.431619   \n",
       "4  Real Bed            moderate          True  ...  38.925627  -77.034596   \n",
       "\n",
       "                                       name     neighbourhood  \\\n",
       "0            Beautiful brownstone 1-bedroom  Brooklyn Heights   \n",
       "1  Superb 3BR Apt Located Near Times Square    Hell's Kitchen   \n",
       "2                          The Garden Oasis            Harlem   \n",
       "3        Beautiful Flat in the Heart of SF!      Lower Haight   \n",
       "4                Great studio in midtown DC  Columbia Heights   \n",
       "\n",
       "  number_of_reviews  review_scores_rating  \\\n",
       "0                 2                 100.0   \n",
       "1                 6                  93.0   \n",
       "2                10                  92.0   \n",
       "3                 0                   NaN   \n",
       "4                 4                  40.0   \n",
       "\n",
       "                                       thumbnail_url  zipcode bedrooms  beds  \n",
       "0  https://a0.muscache.com/im/pictures/6d7cbbf7-c...    11201      1.0   1.0  \n",
       "1  https://a0.muscache.com/im/pictures/348a55fe-4...    10019      3.0   3.0  \n",
       "2  https://a0.muscache.com/im/pictures/6fae5362-9...    10027      1.0   3.0  \n",
       "3  https://a0.muscache.com/im/pictures/72208dad-9...  94117.0      2.0   2.0  \n",
       "4                                                NaN    20009      0.0   1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def p2f(x):\n",
    "    if (x!=''):\n",
    "        return int(x.strip('%')) \n",
    "    else:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "df_full = pd.read_csv(\"train.csv\",converters={'host_response_rate':p2f})\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.411100e+04</td>\n",
       "      <td>74111.000000</td>\n",
       "      <td>74111.000000</td>\n",
       "      <td>73911.000000</td>\n",
       "      <td>55812.000000</td>\n",
       "      <td>74111.000000</td>\n",
       "      <td>74111.000000</td>\n",
       "      <td>74111.000000</td>\n",
       "      <td>57389.000000</td>\n",
       "      <td>74020.000000</td>\n",
       "      <td>73980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.126662e+07</td>\n",
       "      <td>4.782069</td>\n",
       "      <td>3.155146</td>\n",
       "      <td>1.235263</td>\n",
       "      <td>94.351967</td>\n",
       "      <td>38.445958</td>\n",
       "      <td>-92.397525</td>\n",
       "      <td>20.900568</td>\n",
       "      <td>94.067365</td>\n",
       "      <td>1.265793</td>\n",
       "      <td>1.710868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.081735e+06</td>\n",
       "      <td>0.717394</td>\n",
       "      <td>2.153589</td>\n",
       "      <td>0.582044</td>\n",
       "      <td>16.341817</td>\n",
       "      <td>3.080167</td>\n",
       "      <td>21.705322</td>\n",
       "      <td>37.828641</td>\n",
       "      <td>7.836556</td>\n",
       "      <td>0.852143</td>\n",
       "      <td>1.254142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.440000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.338905</td>\n",
       "      <td>-122.511500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.261964e+06</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34.127908</td>\n",
       "      <td>-118.342374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.225415e+07</td>\n",
       "      <td>4.709530</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>40.662138</td>\n",
       "      <td>-76.996965</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.640226e+07</td>\n",
       "      <td>5.220356</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>40.746096</td>\n",
       "      <td>-73.954660</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.123090e+07</td>\n",
       "      <td>7.600402</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>42.390437</td>\n",
       "      <td>-70.985047</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     log_price  accommodates     bathrooms  \\\n",
       "count  7.411100e+04  74111.000000  74111.000000  73911.000000   \n",
       "mean   1.126662e+07      4.782069      3.155146      1.235263   \n",
       "std    6.081735e+06      0.717394      2.153589      0.582044   \n",
       "min    3.440000e+02      0.000000      1.000000      0.000000   \n",
       "25%    6.261964e+06      4.317488      2.000000      1.000000   \n",
       "50%    1.225415e+07      4.709530      2.000000      1.000000   \n",
       "75%    1.640226e+07      5.220356      4.000000      1.000000   \n",
       "max    2.123090e+07      7.600402     16.000000      8.000000   \n",
       "\n",
       "       host_response_rate      latitude     longitude  number_of_reviews  \\\n",
       "count        55812.000000  74111.000000  74111.000000       74111.000000   \n",
       "mean            94.351967     38.445958    -92.397525          20.900568   \n",
       "std             16.341817      3.080167     21.705322          37.828641   \n",
       "min              0.000000     33.338905   -122.511500           0.000000   \n",
       "25%            100.000000     34.127908   -118.342374           1.000000   \n",
       "50%            100.000000     40.662138    -76.996965           6.000000   \n",
       "75%            100.000000     40.746096    -73.954660          23.000000   \n",
       "max            100.000000     42.390437    -70.985047         605.000000   \n",
       "\n",
       "       review_scores_rating      bedrooms          beds  \n",
       "count          57389.000000  74020.000000  73980.000000  \n",
       "mean              94.067365      1.265793      1.710868  \n",
       "std                7.836556      0.852143      1.254142  \n",
       "min               20.000000      0.000000      0.000000  \n",
       "25%               92.000000      1.000000      1.000000  \n",
       "50%               96.000000      1.000000      1.000000  \n",
       "75%              100.000000      1.000000      2.000000  \n",
       "max              100.000000     10.000000     18.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74111 entries, 0 to 74110\n",
      "Data columns (total 29 columns):\n",
      "id                        74111 non-null int64\n",
      "log_price                 74111 non-null float64\n",
      "property_type             74111 non-null object\n",
      "room_type                 74111 non-null object\n",
      "amenities                 74111 non-null object\n",
      "accommodates              74111 non-null int64\n",
      "bathrooms                 73911 non-null float64\n",
      "bed_type                  74111 non-null object\n",
      "cancellation_policy       74111 non-null object\n",
      "cleaning_fee              74111 non-null bool\n",
      "city                      74111 non-null object\n",
      "description               74111 non-null object\n",
      "first_review              58247 non-null object\n",
      "host_has_profile_pic      73923 non-null object\n",
      "host_identity_verified    73923 non-null object\n",
      "host_response_rate        55812 non-null float64\n",
      "host_since                73923 non-null object\n",
      "instant_bookable          74111 non-null object\n",
      "last_review               58284 non-null object\n",
      "latitude                  74111 non-null float64\n",
      "longitude                 74111 non-null float64\n",
      "name                      74111 non-null object\n",
      "neighbourhood             67239 non-null object\n",
      "number_of_reviews         74111 non-null int64\n",
      "review_scores_rating      57389 non-null float64\n",
      "thumbnail_url             65895 non-null object\n",
      "zipcode                   73145 non-null object\n",
      "bedrooms                  74020 non-null float64\n",
      "beds                      73980 non-null float64\n",
      "dtypes: bool(1), float64(8), int64(3), object(17)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separaremos las columnas en distintas categorías pues deberan ser tratadas de maneras distintas. Las columnas \"others\" y \"categorical\" ya están separadas, complete las numéricas y las fechas.\n",
    "\n",
    "¿Qué particularidad tiene las columnas agrupadas en \"otros\" y porque esto nos complicará su utilización?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          int64\n",
       "log_price                 float64\n",
       "property_type              object\n",
       "room_type                  object\n",
       "amenities                  object\n",
       "accommodates                int64\n",
       "bathrooms                 float64\n",
       "bed_type                   object\n",
       "cancellation_policy        object\n",
       "cleaning_fee                 bool\n",
       "city                       object\n",
       "description                object\n",
       "first_review               object\n",
       "host_has_profile_pic       object\n",
       "host_identity_verified     object\n",
       "host_response_rate        float64\n",
       "host_since                 object\n",
       "instant_bookable           object\n",
       "last_review                object\n",
       "latitude                  float64\n",
       "longitude                 float64\n",
       "name                       object\n",
       "neighbourhood              object\n",
       "number_of_reviews           int64\n",
       "review_scores_rating      float64\n",
       "thumbnail_url              object\n",
       "zipcode                    object\n",
       "bedrooms                  float64\n",
       "beds                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "property_type\n",
      "room_type\n",
      "bed_type\n",
      "cancellation_policy\n",
      "cleaning_fee\n",
      "city\n",
      "host_has_profile_pic\n",
      "host_identity_verified\n",
      "instant_bookable\n",
      "neighbourhood\n",
      "zipcode\n"
     ]
    }
   ],
   "source": [
    "other_col = df_full.columns[[4,11,25,21]]\n",
    "cat_col = df_full.columns[[0,2,3,7,8,9,10,13,14,17,22,26]]\n",
    "num_col = df_full.columns[[1,5,6,15,19,20,23,24]]\n",
    "date_col = df_full.columns[[12,16,18]]\n",
    "\n",
    "for col in df_full[cat_col].columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore más en detalle la columna `amenities` y explique por qué sería interesante rescatar la información contenida en ella tomando en cuenta el problema en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {\"Wireless Internet\",\"Air conditioning\",Kitche...\n",
       "1        {\"Wireless Internet\",\"Air conditioning\",Kitche...\n",
       "2        {TV,\"Cable TV\",\"Wireless Internet\",\"Air condit...\n",
       "3        {TV,\"Cable TV\",Internet,\"Wireless Internet\",Ki...\n",
       "4        {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "5        {TV,\"Wireless Internet\",Heating,\"Smoke detecto...\n",
       "6        {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "7        {TV,\"Cable TV\",\"Wireless Internet\",\"Wheelchair...\n",
       "8        {TV,\"Cable TV\",\"Wireless Internet\",\"Pets live ...\n",
       "9        {\"Wireless Internet\",\"Air conditioning\",Kitche...\n",
       "10       {Internet,\"Wireless Internet\",\"Air conditionin...\n",
       "11       {TV,\"Cable TV\",Internet,\"Wireless Internet\",Ki...\n",
       "12       {TV,Internet,\"Wireless Internet\",Kitchen,\"Free...\n",
       "13       {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "14       {Kitchen,Heating,\"Smoke detector\",\"Carbon mono...\n",
       "15       {Internet,\"Wireless Internet\",\"Air conditionin...\n",
       "16       {TV,\"Wireless Internet\",Kitchen,\"Pets allowed\"...\n",
       "17       {Internet,\"Wireless Internet\",\"Air conditionin...\n",
       "18       {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "19       {TV,\"Wireless Internet\",\"Air conditioning\",Kit...\n",
       "20       {\"Cable TV\",Internet,\"Wireless Internet\",\"Air ...\n",
       "21       {Internet,\"Air conditioning\",Kitchen,\"Smoking ...\n",
       "22       {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "23       {Internet,\"Wireless Internet\",\"Air conditionin...\n",
       "24       {TV,\"Wireless Internet\",\"Air conditioning\",Kit...\n",
       "25       {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "26       {TV,\"Wireless Internet\",Pool,Kitchen,\"Elevator...\n",
       "27       {TV,\"Cable TV\",\"Wireless Internet\",\"Air condit...\n",
       "28       {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "29       {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "                               ...                        \n",
       "74081    {TV,\"Wireless Internet\",\"Air conditioning\",Kit...\n",
       "74082    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"F...\n",
       "74083    {TV,\"Wireless Internet\",Kitchen,\"Smoke detecto...\n",
       "74084    {TV,\"Wireless Internet\",\"Air conditioning\",Kit...\n",
       "74085    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "74086    {TV,\"Wireless Internet\",Heating,\"Smoke detecto...\n",
       "74087    {TV,\"Wireless Internet\",\"Air conditioning\",Poo...\n",
       "74088    {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "74089    {TV,\"Cable TV\",Internet,\"Air conditioning\",Poo...\n",
       "74090    {TV,Internet,\"Smoke detector\",\"Wireless Intern...\n",
       "74091    {\"Wireless Internet\",\"Air conditioning\",Kitche...\n",
       "74092    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "74093    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "74094    {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "74095    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "74096    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "74097    {Internet,\"Wireless Internet\",\"Air conditionin...\n",
       "74098    {Internet,\"Wireless Internet\",\"Air conditionin...\n",
       "74099    {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "74100    {Internet,\"Wireless Internet\",\"Air conditionin...\n",
       "74101    {TV,Internet,\"Wireless Internet\",Pool,Kitchen,...\n",
       "74102    {TV,\"Wireless Internet\",\"Air conditioning\",Kit...\n",
       "74103    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "74104    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "74105    {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "74106                                                   {}\n",
       "74107    {TV,\"Cable TV\",Internet,\"Wireless Internet\",Ki...\n",
       "74108    {TV,Internet,\"Wireless Internet\",\"Air conditio...\n",
       "74109    {TV,\"Wireless Internet\",\"Air conditioning\",Kit...\n",
       "74110    {TV,Internet,\"Wireless Internet\",Kitchen,\"Free...\n",
       "Name: amenities, Length: 74111, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.amenities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Amenities como categórica\n",
    "En esta pregunta extraeremos cada una de las `amenities` posibles y la representaremos como una columna categorica, es decir una columna con un 1 si la esa característica aparece como disponible en el anuncio y un 0 en caso contrario. \n",
    "Para esto primero extraiga un conjunto de todas las amenities posibles. Puede utilizar el método `.apply` de las `Series` de pandas para transformar las entradas de la columna a una lista de las _amenities_ como muestra el código. Luego puede usar un `set` para evitar repeticiones inecesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un total de 131 amenities posibles\n"
     ]
    }
   ],
   "source": [
    "amenities_as_lists = df_full['amenities'].apply(lambda x: x.replace(\"{\",'').replace(\"}\",'').replace(\"\\\"\",'').split(','))\n",
    "amenities_set = set()\n",
    "amenities_list= []\n",
    "for lis in amenities_as_lists:\n",
    "    for element in lis:\n",
    "        amenities_set.add(element)\n",
    "        amenities_list.append(element)\n",
    "\n",
    "print(f\"Hay un total de {len(amenities_set)} amenities posibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuente la cantidad de apariciones de cada _amenity_ en el _dataset_. \n",
    "\n",
    "Claramente algunos valores tienen muy pocos ejemplos, lo cual tiene sentido considerando el problema. Optaremos por no considerar las amenities que aparezcan en menos de 1000 anuncios. \n",
    "\n",
    "Cree ahora nuevas columnas en el _DataFrame_, donde cada columna corresponda a una _amenity_ que cumpla el criterio y se represente binariamente, como muestra el esqueleto de código.\n",
    "\n",
    "Aprovecharemos de eliminar las otras columas `others` pues para el alcance de esta tarea no vale la pena considerarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, amenity in enumerate(amenities_set):\n",
    "    if (amenities_list.count(amenity)>=1000):\n",
    "        df_full[str(amenity)] = df_full['amenities'].apply(lambda x: 1 if amenity in x else 0)\n",
    "        \n",
    "df= df_full.drop(columns=other_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>Gym</th>\n",
       "      <th>Suitable for events</th>\n",
       "      <th>Cooking basics</th>\n",
       "      <th>Bathtub</th>\n",
       "      <th>Hot water</th>\n",
       "      <th>Shampoo</th>\n",
       "      <th>Luggage dropoff allowed</th>\n",
       "      <th>Dryer</th>\n",
       "      <th>Smoke detector</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6901257</td>\n",
       "      <td>5.010635</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6304928</td>\n",
       "      <td>5.129899</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7919400</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13418779</td>\n",
       "      <td>6.620073</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>SF</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3808709</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>DC</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  log_price property_type        room_type  accommodates  \\\n",
       "0   6901257   5.010635     Apartment  Entire home/apt             3   \n",
       "1   6304928   5.129899     Apartment  Entire home/apt             7   \n",
       "2   7919400   4.976734     Apartment  Entire home/apt             5   \n",
       "3  13418779   6.620073         House  Entire home/apt             4   \n",
       "4   3808709   4.744932     Apartment  Entire home/apt             2   \n",
       "\n",
       "   bathrooms  bed_type cancellation_policy  cleaning_fee city  ... Gym  \\\n",
       "0        1.0  Real Bed              strict          True  NYC  ...   0   \n",
       "1        1.0  Real Bed              strict          True  NYC  ...   0   \n",
       "2        1.0  Real Bed            moderate          True  NYC  ...   0   \n",
       "3        1.0  Real Bed            flexible          True   SF  ...   0   \n",
       "4        1.0  Real Bed            moderate          True   DC  ...   0   \n",
       "\n",
       "  Suitable for events Cooking basics  Bathtub Hot water Shampoo  \\\n",
       "0                   0              0        0         0       0   \n",
       "1                   0              0        0         0       1   \n",
       "2                   0              0        0         0       1   \n",
       "3                   0              0        0         0       0   \n",
       "4                   0              0        0         0       1   \n",
       "\n",
       "  Luggage dropoff allowed  Dryer  Smoke detector TV  \n",
       "0                       0      0               0  0  \n",
       "1                       0      1               1  0  \n",
       "2                       0      0               1  1  \n",
       "3                       0      1               1  1  \n",
       "4                       0      0               1  1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Otras variables categoricas\n",
    "Para cada una de las variables categoricas, cuente cuantos valores únicos tiene en el dataset. ¿Cuales la llaman la atención y por qué? ¿Tiene esto sentido con la naturaleza del problema?\n",
    "\n",
    "Eliminaremos las variables `id` pues solo sirve para identificar cada anuncio y la variable `zipcode` pues representa una información similar a la de `neighbourhood` y en la realidad los usuarios se interesan más por la segunda que por la primera. \n",
    "\n",
    "Cuente cuantos valores tiene cada clase de algunas variables categóricas que le interesen, usando el metodo `.value_counts` de las `Series`.\n",
    "\n",
    "Contaremos también los valores NA (valores ausentes o corrompidos) en todo el dataset con el código dentro del `print`. Eliminaremos todos aquellas variables que tengan más de un 10% de valores ausentes, es decir las 4 columnas presentes en el código. Para evitar problemas más adelante, complete el resto de los valores ausentes con el valor 0, usando el metodo `.fillna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_rate                            18299\n",
      "review_scores_rating                          16722\n",
      "first_review                                  15864\n",
      "last_review                                   15827\n",
      "neighbourhood                                  6872\n",
      "zipcode                                         966\n",
      "bathrooms                                       200\n",
      "host_has_profile_pic                            188\n",
      "host_identity_verified                          188\n",
      "host_since                                      188\n",
      "beds                                            131\n",
      "bedrooms                                         91\n",
      "Patio or balcony                                  0\n",
      "Hangers                                           0\n",
      "Wide doorway                                      0\n",
      "Oven                                              0\n",
      "Essentials                                        0\n",
      "Wheelchair accessible                             0\n",
      "Laptop friendly workspace                         0\n",
      "Safety card                                       0\n",
      "Self Check-In                                     0\n",
      "Free parking on premises                          0\n",
      "Lockbox                                           0\n",
      "Dog(s)                                            0\n",
      "Bed linens                                        0\n",
      "Carbon monoxide detector                          0\n",
      "Lock on bedroom door                              0\n",
      "Refrigerator                                      0\n",
      "Fire extinguisher                                 0\n",
      "TV                                                0\n",
      "                                              ...  \n",
      "Cooking basics                                    0\n",
      "Bathtub                                           0\n",
      "Hot water                                         0\n",
      "Shampoo                                           0\n",
      "Luggage dropoff allowed                           0\n",
      "Dryer                                             0\n",
      "Doorman                                           0\n",
      "Indoor fireplace                                  0\n",
      "Garden or backyard                                0\n",
      "Internet                                          0\n",
      "Pool                                              0\n",
      "Step-free access                                  0\n",
      "Pets live on this property                        0\n",
      "Long term stays allowed                           0\n",
      "Air conditioning                                  0\n",
      "Kitchen                                           0\n",
      "Pack ’n Play/travel crib                          0\n",
      "Elevator                                          0\n",
      "Iron                                              0\n",
      "Hot tub                                           0\n",
      "Microwave                                         0\n",
      "Heating                                           0\n",
      "Private living room                               0\n",
      "Keypad                                            0\n",
      "Hair dryer                                        0\n",
      "Wireless Internet                                 0\n",
      "translation missing: en.hosting_amenity_50        0\n",
      "Dishes and silverware                             0\n",
      "Host greets you                                   0\n",
      "id                                                0\n",
      "Length: 94, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>city</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>...</th>\n",
       "      <th>Gym</th>\n",
       "      <th>Suitable for events</th>\n",
       "      <th>Cooking basics</th>\n",
       "      <th>Bathtub</th>\n",
       "      <th>Hot water</th>\n",
       "      <th>Shampoo</th>\n",
       "      <th>Luggage dropoff allowed</th>\n",
       "      <th>Dryer</th>\n",
       "      <th>Smoke detector</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.010635</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.129899</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.976734</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.620073</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>SF</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.744932</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>DC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.442651</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>SF</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.418841</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>SF</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.583519</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.605170</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.010635</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.248495</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.298317</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>DC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.955827</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.094345</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.317488</td>\n",
       "      <td>Loft</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>False</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.595120</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>Boston</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.882802</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.595120</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.382027</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.688879</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.905275</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.007333</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.956545</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>DC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.003946</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.553877</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.003946</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.192957</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.653960</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74081</th>\n",
       "      <td>6.907755</td>\n",
       "      <td>Other</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74082</th>\n",
       "      <td>4.174387</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>SF</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74083</th>\n",
       "      <td>5.010635</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>False</td>\n",
       "      <td>SF</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74084</th>\n",
       "      <td>5.843544</td>\n",
       "      <td>Other</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>False</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74085</th>\n",
       "      <td>4.653960</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>False</td>\n",
       "      <td>DC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74086</th>\n",
       "      <td>4.174387</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74087</th>\n",
       "      <td>4.477337</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74088</th>\n",
       "      <td>4.905275</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>False</td>\n",
       "      <td>DC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74089</th>\n",
       "      <td>4.605170</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74090</th>\n",
       "      <td>4.317488</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>False</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74091</th>\n",
       "      <td>5.010635</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74092</th>\n",
       "      <td>4.700480</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74093</th>\n",
       "      <td>4.948760</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>DC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74094</th>\n",
       "      <td>3.688879</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74095</th>\n",
       "      <td>4.382027</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>False</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74096</th>\n",
       "      <td>3.912023</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>False</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74097</th>\n",
       "      <td>4.700480</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74098</th>\n",
       "      <td>4.553877</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74099</th>\n",
       "      <td>4.276666</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74100</th>\n",
       "      <td>4.605170</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74101</th>\n",
       "      <td>4.584967</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74102</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>Villa</td>\n",
       "      <td>Shared room</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>False</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74103</th>\n",
       "      <td>5.135798</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>SF</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74104</th>\n",
       "      <td>4.356709</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74105</th>\n",
       "      <td>4.248495</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74106</th>\n",
       "      <td>4.605170</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>flexible</td>\n",
       "      <td>False</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74107</th>\n",
       "      <td>5.043425</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74108</th>\n",
       "      <td>5.220356</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74109</th>\n",
       "      <td>5.273000</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>True</td>\n",
       "      <td>NYC</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74110</th>\n",
       "      <td>4.852030</td>\n",
       "      <td>Boat</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "      <td>LA</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74111 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_price property_type        room_type  accommodates  bathrooms  \\\n",
       "0       5.010635     Apartment  Entire home/apt             3        1.0   \n",
       "1       5.129899     Apartment  Entire home/apt             7        1.0   \n",
       "2       4.976734     Apartment  Entire home/apt             5        1.0   \n",
       "3       6.620073         House  Entire home/apt             4        1.0   \n",
       "4       4.744932     Apartment  Entire home/apt             2        1.0   \n",
       "5       4.442651     Apartment     Private room             2        1.0   \n",
       "6       4.418841     Apartment  Entire home/apt             3        1.0   \n",
       "7       4.787492   Condominium  Entire home/apt             2        1.0   \n",
       "8       4.787492         House     Private room             2        1.0   \n",
       "9       3.583519         House     Private room             2        1.0   \n",
       "10      4.605170     Apartment     Private room             2        1.0   \n",
       "11      5.010635         House  Entire home/apt             4        1.5   \n",
       "12      4.248495     Apartment     Private room             2        1.0   \n",
       "13      5.298317     Apartment  Entire home/apt             6        1.5   \n",
       "14      4.955827     Apartment  Entire home/apt             2        1.0   \n",
       "15      4.094345     Apartment     Private room             2        1.5   \n",
       "16      4.317488          Loft     Private room             2        1.0   \n",
       "17      4.595120     Townhouse     Private room             2        2.0   \n",
       "18      4.882802     Apartment  Entire home/apt             2        1.0   \n",
       "19      4.595120         House  Entire home/apt             8        1.0   \n",
       "20      4.382027         House     Private room             2        1.0   \n",
       "21      3.688879         House     Private room             2        1.5   \n",
       "22      4.905275     Apartment  Entire home/apt             4        1.0   \n",
       "23      4.007333         House     Private room             2        1.0   \n",
       "24      6.956545     Apartment  Entire home/apt             4        1.0   \n",
       "25      5.003946     Apartment  Entire home/apt             6        1.0   \n",
       "26      4.553877     Apartment  Entire home/apt             2        1.0   \n",
       "27      5.003946     Apartment  Entire home/apt             4        1.0   \n",
       "28      5.192957     Apartment  Entire home/apt             3        1.0   \n",
       "29      4.653960     Apartment     Private room             3        1.0   \n",
       "...          ...           ...              ...           ...        ...   \n",
       "74081   6.907755         Other  Entire home/apt            16        1.0   \n",
       "74082   4.174387         House     Private room             1        1.0   \n",
       "74083   5.010635     Apartment     Private room             2        1.0   \n",
       "74084   5.843544         Other  Entire home/apt             4        1.0   \n",
       "74085   4.653960     Apartment  Entire home/apt             2        1.0   \n",
       "74086   4.174387         House     Private room             2        1.0   \n",
       "74087   4.477337     Apartment  Entire home/apt             4        1.0   \n",
       "74088   4.905275         House  Entire home/apt             5        2.5   \n",
       "74089   4.605170         House     Private room             2        1.0   \n",
       "74090   4.317488         House     Private room             2        1.0   \n",
       "74091   5.010635     Apartment  Entire home/apt             2        1.0   \n",
       "74092   4.700480     Apartment  Entire home/apt             4        2.0   \n",
       "74093   4.948760         House  Entire home/apt             4        1.0   \n",
       "74094   3.688879     Apartment     Private room             2        1.0   \n",
       "74095   4.382027     Apartment  Entire home/apt             2        1.0   \n",
       "74096   3.912023     Apartment     Private room             2        1.0   \n",
       "74097   4.700480     Apartment     Private room             2        1.0   \n",
       "74098   4.553877     Apartment  Entire home/apt             4        1.0   \n",
       "74099   4.276666   Condominium     Private room             2        1.0   \n",
       "74100   4.605170     Apartment     Private room             2        1.0   \n",
       "74101   4.584967     Apartment     Private room             1        1.0   \n",
       "74102   4.110874         Villa      Shared room            10        3.0   \n",
       "74103   5.135798     Apartment  Entire home/apt             2        1.0   \n",
       "74104   4.356709     Apartment  Entire home/apt             2        1.0   \n",
       "74105   4.248495         House     Private room             2        1.0   \n",
       "74106   4.605170     Apartment     Private room             1        1.0   \n",
       "74107   5.043425     Apartment  Entire home/apt             4        2.0   \n",
       "74108   5.220356     Apartment  Entire home/apt             5        1.0   \n",
       "74109   5.273000     Apartment  Entire home/apt             2        1.0   \n",
       "74110   4.852030          Boat  Entire home/apt             4        1.0   \n",
       "\n",
       "       bed_type cancellation_policy  cleaning_fee     city  \\\n",
       "0      Real Bed              strict          True      NYC   \n",
       "1      Real Bed              strict          True      NYC   \n",
       "2      Real Bed            moderate          True      NYC   \n",
       "3      Real Bed            flexible          True       SF   \n",
       "4      Real Bed            moderate          True       DC   \n",
       "5      Real Bed              strict          True       SF   \n",
       "6      Real Bed            moderate          True       LA   \n",
       "7      Real Bed            moderate          True       LA   \n",
       "8      Real Bed            moderate          True       SF   \n",
       "9      Real Bed            moderate          True       LA   \n",
       "10     Real Bed              strict          True      NYC   \n",
       "11     Real Bed              strict          True       LA   \n",
       "12     Real Bed            flexible          True       LA   \n",
       "13     Real Bed              strict          True       DC   \n",
       "14     Real Bed              strict          True       LA   \n",
       "15     Real Bed            moderate          True  Chicago   \n",
       "16     Real Bed              strict         False  Chicago   \n",
       "17     Real Bed              strict          True   Boston   \n",
       "18     Real Bed              strict          True      NYC   \n",
       "19     Real Bed              strict          True      NYC   \n",
       "20     Real Bed              strict          True       LA   \n",
       "21     Real Bed              strict          True      NYC   \n",
       "22     Real Bed            moderate          True       LA   \n",
       "23     Real Bed            moderate          True       LA   \n",
       "24     Real Bed            moderate          True       DC   \n",
       "25     Real Bed              strict          True      NYC   \n",
       "26     Real Bed            flexible          True       LA   \n",
       "27     Real Bed              strict          True      NYC   \n",
       "28     Real Bed            flexible          True       LA   \n",
       "29     Real Bed              strict          True      NYC   \n",
       "...         ...                 ...           ...      ...   \n",
       "74081  Real Bed            moderate         False       LA   \n",
       "74082  Real Bed            flexible          True       SF   \n",
       "74083  Real Bed            flexible         False       SF   \n",
       "74084  Real Bed              strict         False      NYC   \n",
       "74085  Real Bed            flexible         False       DC   \n",
       "74086  Real Bed              strict          True      NYC   \n",
       "74087  Real Bed              strict          True       LA   \n",
       "74088  Real Bed            flexible         False       DC   \n",
       "74089  Real Bed              strict          True       LA   \n",
       "74090  Real Bed            flexible         False      NYC   \n",
       "74091  Real Bed            moderate         False      NYC   \n",
       "74092  Real Bed              strict          True  Chicago   \n",
       "74093  Real Bed              strict          True       DC   \n",
       "74094  Real Bed              strict          True      NYC   \n",
       "74095  Real Bed            flexible         False      NYC   \n",
       "74096  Real Bed            flexible         False      NYC   \n",
       "74097  Real Bed            flexible          True      NYC   \n",
       "74098  Real Bed            flexible          True       LA   \n",
       "74099  Real Bed            moderate          True       LA   \n",
       "74100  Real Bed              strict          True      NYC   \n",
       "74101  Real Bed            moderate          True       LA   \n",
       "74102  Real Bed            flexible         False       LA   \n",
       "74103  Real Bed            moderate          True       SF   \n",
       "74104  Real Bed              strict          True  Chicago   \n",
       "74105  Real Bed            moderate          True       LA   \n",
       "74106  Real Bed            flexible         False      NYC   \n",
       "74107  Real Bed            moderate          True       LA   \n",
       "74108  Real Bed            moderate          True      NYC   \n",
       "74109  Real Bed              strict          True      NYC   \n",
       "74110  Real Bed            moderate         False       LA   \n",
       "\n",
       "      host_has_profile_pic  ... Gym Suitable for events  Cooking basics  \\\n",
       "0                        t  ...   0                   0               0   \n",
       "1                        t  ...   0                   0               0   \n",
       "2                        t  ...   0                   0               0   \n",
       "3                        t  ...   0                   0               0   \n",
       "4                        t  ...   0                   0               0   \n",
       "5                        t  ...   0                   0               0   \n",
       "6                        t  ...   1                   0               0   \n",
       "7                        t  ...   0                   0               0   \n",
       "8                        t  ...   0                   0               0   \n",
       "9                        t  ...   0                   0               0   \n",
       "10                       t  ...   0                   0               0   \n",
       "11                       t  ...   0                   0               0   \n",
       "12                       t  ...   0                   0               0   \n",
       "13                       t  ...   0                   0               0   \n",
       "14                       t  ...   0                   0               0   \n",
       "15                       t  ...   0                   0               0   \n",
       "16                       t  ...   0                   1               0   \n",
       "17                       t  ...   0                   0               0   \n",
       "18                       t  ...   0                   0               0   \n",
       "19                       t  ...   0                   0               1   \n",
       "20                       t  ...   0                   0               0   \n",
       "21                       t  ...   0                   0               0   \n",
       "22                       t  ...   1                   0               0   \n",
       "23                       t  ...   0                   0               0   \n",
       "24                       t  ...   0                   0               0   \n",
       "25                       t  ...   0                   0               1   \n",
       "26                       t  ...   0                   0               0   \n",
       "27                       t  ...   0                   0               0   \n",
       "28                       t  ...   0                   0               0   \n",
       "29                       t  ...   0                   0               0   \n",
       "...                    ...  ...  ..                 ...             ...   \n",
       "74081                    t  ...   0                   1               0   \n",
       "74082                    t  ...   0                   0               0   \n",
       "74083                    t  ...   0                   0               0   \n",
       "74084                    t  ...   0                   0               0   \n",
       "74085                    t  ...   1                   0               0   \n",
       "74086                    t  ...   0                   0               0   \n",
       "74087                    t  ...   0                   0               0   \n",
       "74088                    t  ...   0                   0               0   \n",
       "74089                    t  ...   0                   1               0   \n",
       "74090                    t  ...   0                   0               0   \n",
       "74091                    t  ...   0                   0               0   \n",
       "74092                    t  ...   0                   0               0   \n",
       "74093                    t  ...   0                   0               0   \n",
       "74094                    t  ...   0                   0               0   \n",
       "74095                    t  ...   0                   0               0   \n",
       "74096                    t  ...   0                   0               0   \n",
       "74097                    t  ...   0                   0               0   \n",
       "74098                    t  ...   1                   0               0   \n",
       "74099                    t  ...   0                   0               0   \n",
       "74100                    t  ...   0                   0               0   \n",
       "74101                    t  ...   0                   0               0   \n",
       "74102                    t  ...   0                   0               0   \n",
       "74103                    t  ...   1                   0               0   \n",
       "74104                    t  ...   1                   0               0   \n",
       "74105                    t  ...   0                   0               0   \n",
       "74106                    t  ...   0                   0               0   \n",
       "74107                    t  ...   0                   0               0   \n",
       "74108                    t  ...   1                   0               1   \n",
       "74109                    t  ...   0                   0               0   \n",
       "74110                    t  ...   0                   0               0   \n",
       "\n",
       "       Bathtub Hot water  Shampoo  Luggage dropoff allowed  Dryer  \\\n",
       "0            0         0        0                        0      0   \n",
       "1            0         0        1                        0      1   \n",
       "2            0         0        1                        0      0   \n",
       "3            0         0        0                        0      1   \n",
       "4            0         0        1                        0      0   \n",
       "5            0         0        0                        0      0   \n",
       "6            0         0        1                        0      1   \n",
       "7            0         0        1                        0      1   \n",
       "8            0         1        1                        0      0   \n",
       "9            0         0        1                        0      0   \n",
       "10           0         0        0                        0      1   \n",
       "11           0         0        1                        0      1   \n",
       "12           0         0        1                        0      1   \n",
       "13           0         0        1                        0      1   \n",
       "14           0         0        0                        0      0   \n",
       "15           0         0        0                        0      1   \n",
       "16           0         0        0                        0      1   \n",
       "17           0         0        1                        0      0   \n",
       "18           0         0        1                        0      0   \n",
       "19           0         1        0                        0      0   \n",
       "20           0         0        1                        0      1   \n",
       "21           0         0        0                        0      0   \n",
       "22           0         0        1                        0      1   \n",
       "23           0         0        1                        0      0   \n",
       "24           0         0        0                        0      1   \n",
       "25           1         1        1                        1      0   \n",
       "26           0         0        0                        0      1   \n",
       "27           0         0        1                        0      1   \n",
       "28           0         0        1                        0      1   \n",
       "29           0         0        1                        0      1   \n",
       "...        ...       ...      ...                      ...    ...   \n",
       "74081        0         0        0                        0      0   \n",
       "74082        0         0        1                        0      0   \n",
       "74083        0         0        0                        0      0   \n",
       "74084        0         0        1                        0      0   \n",
       "74085        0         0        1                        0      1   \n",
       "74086        0         0        0                        0      0   \n",
       "74087        0         0        1                        0      1   \n",
       "74088        0         0        1                        0      1   \n",
       "74089        0         0        0                        0      1   \n",
       "74090        0         0        1                        0      0   \n",
       "74091        0         0        0                        0      0   \n",
       "74092        0         0        1                        0      1   \n",
       "74093        0         0        1                        0      0   \n",
       "74094        0         0        1                        0      0   \n",
       "74095        0         0        1                        0      0   \n",
       "74096        0         0        0                        0      0   \n",
       "74097        0         0        1                        0      1   \n",
       "74098        0         0        0                        0      1   \n",
       "74099        0         0        1                        0      1   \n",
       "74100        0         0        1                        0      1   \n",
       "74101        0         0        1                        0      1   \n",
       "74102        0         0        1                        0      1   \n",
       "74103        0         0        1                        0      0   \n",
       "74104        0         0        1                        0      1   \n",
       "74105        0         0        0                        0      1   \n",
       "74106        0         0        0                        0      0   \n",
       "74107        0         0        1                        0      1   \n",
       "74108        0         1        1                        0      1   \n",
       "74109        0         0        1                        0      1   \n",
       "74110        0         0        1                        0      0   \n",
       "\n",
       "       Smoke detector  TV  \n",
       "0                   0   0  \n",
       "1                   1   0  \n",
       "2                   1   1  \n",
       "3                   1   1  \n",
       "4                   1   1  \n",
       "5                   1   1  \n",
       "6                   1   1  \n",
       "7                   1   1  \n",
       "8                   1   1  \n",
       "9                   0   0  \n",
       "10                  1   0  \n",
       "11                  1   1  \n",
       "12                  1   1  \n",
       "13                  1   1  \n",
       "14                  1   0  \n",
       "15                  0   0  \n",
       "16                  1   1  \n",
       "17                  1   0  \n",
       "18                  1   1  \n",
       "19                  1   1  \n",
       "20                  1   1  \n",
       "21                  1   0  \n",
       "22                  1   1  \n",
       "23                  1   0  \n",
       "24                  1   1  \n",
       "25                  1   1  \n",
       "26                  1   1  \n",
       "27                  1   1  \n",
       "28                  1   1  \n",
       "29                  0   1  \n",
       "...               ...  ..  \n",
       "74081               1   1  \n",
       "74082               1   1  \n",
       "74083               1   1  \n",
       "74084               1   1  \n",
       "74085               1   1  \n",
       "74086               1   1  \n",
       "74087               1   1  \n",
       "74088               1   1  \n",
       "74089               1   1  \n",
       "74090               1   1  \n",
       "74091               1   0  \n",
       "74092               1   1  \n",
       "74093               1   1  \n",
       "74094               1   1  \n",
       "74095               0   1  \n",
       "74096               1   1  \n",
       "74097               1   0  \n",
       "74098               1   0  \n",
       "74099               1   1  \n",
       "74100               1   0  \n",
       "74101               1   1  \n",
       "74102               1   1  \n",
       "74103               1   1  \n",
       "74104               1   1  \n",
       "74105               1   1  \n",
       "74106               0   0  \n",
       "74107               1   1  \n",
       "74108               1   1  \n",
       "74109               1   1  \n",
       "74110               1   1  \n",
       "\n",
       "[74111 rows x 87 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(df.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "df = df.drop(columns=['host_response_rate','review_scores_rating', 'first_review', 'last_review','id','zipcode','host_since'])\n",
    "df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora transformaremos todas las variables categoricas restantes a una representación en _one hot vector_. Para esto odemos utilizar la función `to_categorical` propuesta por keras. Puede apoyarse de las lineas de código abajo. No olvide eliminar las columnas originales del _dataframe_.\n",
    "\n",
    "Por último, en este caso optaremos por eliminar las columnas correspondientes a alguna fecha, pues no resultan significativas para el problema y la cantidad de variables disponibles son suficientes para hacer una exploración de las redes densas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_price                                     float64\n",
       "property_type                                  object\n",
       "room_type                                      object\n",
       "accommodates                                    int64\n",
       "bathrooms                                     float64\n",
       "bed_type                                       object\n",
       "cancellation_policy                            object\n",
       "cleaning_fee                                     bool\n",
       "city                                           object\n",
       "host_has_profile_pic                           object\n",
       "host_identity_verified                         object\n",
       "instant_bookable                               object\n",
       "latitude                                      float64\n",
       "longitude                                     float64\n",
       "neighbourhood                                  object\n",
       "number_of_reviews                               int64\n",
       "bedrooms                                      float64\n",
       "beds                                          float64\n",
       "Coffee maker                                    int64\n",
       "Extra pillows and blankets                      int64\n",
       "Cable TV                                        int64\n",
       "Dog(s)                                          int64\n",
       "Fire extinguisher                               int64\n",
       "Hangers                                         int64\n",
       "Wide doorway                                    int64\n",
       "Oven                                            int64\n",
       "Wheelchair accessible                           int64\n",
       "Patio or balcony                                int64\n",
       "Self Check-In                                   int64\n",
       "Lockbox                                         int64\n",
       "                                               ...   \n",
       "Wireless Internet                               int64\n",
       "translation missing: en.hosting_amenity_50      int64\n",
       "Dishes and silverware                           int64\n",
       "Host greets you                                 int64\n",
       "Internet                                        int64\n",
       "Garden or backyard                              int64\n",
       "Indoor fireplace                                int64\n",
       "Doorman                                         int64\n",
       "Stove                                           int64\n",
       "24-hour check-in                                int64\n",
       "Washer                                          int64\n",
       "Pets allowed                                    int64\n",
       "Dishwasher                                      int64\n",
       "Room-darkening shades                           int64\n",
       "translation missing: en.hosting_amenity_49      int64\n",
       "Children’s books and toys                       int64\n",
       "First aid kit                                   int64\n",
       "Family/kid friendly                             int64\n",
       "Breakfast                                       int64\n",
       "Buzzer/wireless intercom                        int64\n",
       "Gym                                             int64\n",
       "Suitable for events                             int64\n",
       "Cooking basics                                  int64\n",
       "Bathtub                                         int64\n",
       "Hot water                                       int64\n",
       "Shampoo                                         int64\n",
       "Luggage dropoff allowed                         int64\n",
       "Dryer                                           int64\n",
       "Smoke detector                                  int64\n",
       "TV                                              int64\n",
       "Length: 87, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "aux=df\n",
    "\n",
    "for col in df.columns[[1,2,5,6,8,9,10,11,14]]:\n",
    "    onehot = to_categorical(df[col].astype('category').cat.codes)\n",
    "    aux[[col + '_' + str(i) for i in range(onehot.shape[1])]] = pd.DataFrame(onehot)\n",
    "df=aux   \n",
    "df=df.drop(columns = df.columns[[1,2,5,6,8,9,10,11,14]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_price                     float64\n",
       "accommodates                    int64\n",
       "bathrooms                     float64\n",
       "cleaning_fee                     bool\n",
       "latitude                      float64\n",
       "longitude                     float64\n",
       "number_of_reviews               int64\n",
       "bedrooms                      float64\n",
       "beds                          float64\n",
       "Coffee maker                    int64\n",
       "Extra pillows and blankets      int64\n",
       "Cable TV                        int64\n",
       "Dog(s)                          int64\n",
       "Fire extinguisher               int64\n",
       "Hangers                         int64\n",
       "Wide doorway                    int64\n",
       "Oven                            int64\n",
       "Wheelchair accessible           int64\n",
       "Patio or balcony                int64\n",
       "Self Check-In                   int64\n",
       "Lockbox                         int64\n",
       "Carbon monoxide detector        int64\n",
       "Lock on bedroom door            int64\n",
       "Refrigerator                    int64\n",
       "Free parking on premises        int64\n",
       "Bed linens                      int64\n",
       "Safety card                     int64\n",
       "Laptop friendly workspace       int64\n",
       "Essentials                      int64\n",
       "Private entrance                int64\n",
       "                               ...   \n",
       "neighbourhood_589             float32\n",
       "neighbourhood_590             float32\n",
       "neighbourhood_591             float32\n",
       "neighbourhood_592             float32\n",
       "neighbourhood_593             float32\n",
       "neighbourhood_594             float32\n",
       "neighbourhood_595             float32\n",
       "neighbourhood_596             float32\n",
       "neighbourhood_597             float32\n",
       "neighbourhood_598             float32\n",
       "neighbourhood_599             float32\n",
       "neighbourhood_600             float32\n",
       "neighbourhood_601             float32\n",
       "neighbourhood_602             float32\n",
       "neighbourhood_603             float32\n",
       "neighbourhood_604             float32\n",
       "neighbourhood_605             float32\n",
       "neighbourhood_606             float32\n",
       "neighbourhood_607             float32\n",
       "neighbourhood_608             float32\n",
       "neighbourhood_609             float32\n",
       "neighbourhood_610             float32\n",
       "neighbourhood_611             float32\n",
       "neighbourhood_612             float32\n",
       "neighbourhood_613             float32\n",
       "neighbourhood_614             float32\n",
       "neighbourhood_615             float32\n",
       "neighbourhood_616             float32\n",
       "neighbourhood_617             float32\n",
       "neighbourhood_618             float32\n",
       "Length: 757, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d Estandarización y Train Test Split\n",
    "En esta pregunta nos ocuparemos de separar el _dataset_ en los conjuntos de entrenamiento, validación y test y estandarizar los datos. Para esto puede utilizar la librería sklearn, en particular las funciones `StandarScaler` y `train_test_split`.\n",
    "\n",
    "Para esto separe primero el dataset en $X$ e $Y$. Luego separe los datos considerando un $70\\%$ de ellos para entrenamiento, un $20\\%$ para validación y un $10\\%$ para test. Finalmente ajuste los _scalers_ con los datos de entrenamiento y transforme los datos. \n",
    "\n",
    "- ¿Qué operación matemática realiza `StandarScaler` al momento de tranformar los datos? \n",
    "- ¿Por qué debemos transformar los datos de validación y de test con el _scaler_ ajustado a los datos de entrenamiento? \n",
    "- ¿Qué estamos tratando de representar en esta separación en conjuntos de entrenamiento, validación y test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x=df.drop(columns=['log_price'])\n",
    "y=df['log_price']\n",
    "x_tr, x_test, y_tr, y_test  = train_test_split(x, y, test_size=0.1, random_state=1)\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_tr, y_tr, test_size=0.2/0.9, random_state=1)\n",
    "y_tr=np.array(y_tr)\n",
    "y_val=np.array(y_val)\n",
    "y_val=np.array(y_val)\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(x_tr)\n",
    "x_tr = scaler_x.transform(x_tr)\n",
    "x_val = scaler_x.transform(x_val)\n",
    "x_test = scaler_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.e Primera Red\n",
    "En esta pregunta construiremos y entrenaremos una primera red neuronal. Para esto utilizaremos la librería keras que se ocupa de crear, compilar y entrenar los modelos de manera simple. Esta libreria puede conectarse a distintos _backend_ que proveen el _framework_ para realizar efectivamente las operaciones necesarias por la red. Los más usuales son _TensorFlow_ y _Theano_, sin embargo en el último tiempo _TensorFlow_ ha tenido una gran adopción por diversos motivos, por lo cual la recomendación es instalar y utilizar TensorFlow. Keras se encargará por lo tanto de crear los modelos y al momento de compilarlos se instanciaran estos en una sesión de TensorFlow. \n",
    "\n",
    "Esta primera red será una red de una capa oculta con $256$ neuronas, activación ReLu. Para esta red y todas las demas utilizaremos la función de pérdida _Mean Square Error_ para obtener resultados comparables entre distintos modelos. Para entrenar esta red utilizaremos Gradiente Descendente Estocástico con un _Learn Rate_ de 0.002. Finalmente entrenaremos esta red por unas 20 _epochs_. \n",
    "\n",
    "Construya la red basandose en el código y la documentación de keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "ANN = Sequential()\n",
    "\n",
    "# Hidden Layer\n",
    "ANN.add(\n",
    "    Dense(\n",
    "        units = 256, \n",
    "        activation = 'relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Output Layer\n",
    "ANN.add(\n",
    "    Dense(\n",
    "       units = 1\n",
    "        # no need for activation (i.e. linear activation) considering the range of the output... \n",
    "    )\n",
    ")\n",
    "\n",
    "ANN.compile(\n",
    "    optimizer=SGD(lr=0.002),\n",
    "    loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma fácil de instanciar la red es la propuesta en el codigo abajo, es decir entrenar la red por 0 _epochs_. Una red instanciada nos permite utilizar el método `.summary` para ver su número de parametros y los tamaños de cada capa. \n",
    "\n",
    "Explique el número de parámetros presentes en esta red, es decir: ¿Cómo a partir de la dimensión del _Input_ y el número de neuronas obtenemos ese número de parámetros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               193792    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 194,049\n",
      "Trainable params: 194,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ANN.fit(x_tr, y_tr, epochs=0)\n",
    "ANN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrene la red por 20 _epochs_, guardando el `history` que retorna el metodo `.fit`.\n",
    "\n",
    "Grafique como varian los errores de validación y de entrenamiento a lo largo de las _epochs_. Comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51876 samples, validate on 14823 samples\n",
      "Epoch 1/20\n",
      "51876/51876 [==============================] - 4s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "51876/51876 [==============================] - 5s 90us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "51876/51876 [==============================] - 4s 78us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "51876/51876 [==============================] - 4s 77us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "51876/51876 [==============================] - 4s 79us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "51876/51876 [==============================] - 5s 89us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "51876/51876 [==============================] - 4s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "51876/51876 [==============================] - 4s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "51876/51876 [==============================] - 4s 85us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "51876/51876 [==============================] - 5s 91us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "51876/51876 [==============================] - 4s 86us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "51876/51876 [==============================] - 4s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "51876/51876 [==============================] - 4s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "51876/51876 [==============================] - 4s 82us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "51876/51876 [==============================] - 4s 84us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "51876/51876 [==============================] - 5s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "51876/51876 [==============================] - 5s 88us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "51876/51876 [==============================] - 4s 80us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "51876/51876 [==============================] - 4s 83us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "51876/51876 [==============================] - 4s 81us/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = ANN.fit(x_tr, y_tr, epochs=20, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan],\n",
       " 'loss': [nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree y entrene nuevamente la red, esta vez cambiando el _learn rate_ utilizado para el SGD. Pruebe a lo menos dos valores mayores y dos valores menores al elegido anteriormente. Note que para valores mayores al propuesto puede comenzar a observar fenómeno de divergencia, por lo cual es recomendable agregarle a la red un _calback_, es decir una función que verifica estados y comportamientos de la red mientras se entrena, en particular `TerminateOnNaN`, el cual interrumpirá el proceso de entrenamiento si encuentra un valor NaN. \n",
    "\n",
    "Grafique el comportamiento de los errores de validación y entrenamiento para a lo menos un valor mayor y uno menor al original y comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TerminateOnNaN\n",
    "\n",
    "# . . . \n",
    "\n",
    "history = ANN.fit( # . . .\n",
    "         callbacks=[TerminateOnNaN]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.f Activación y regularizadores $l$1 $l$2\n",
    "En esta pregunta se les propone explorar distintas funciones de activación o de regularización usual. Por lo extenso de la tarea se les propone elegir una de las dos exploraciones. En ambos casos deben entrenar la misma red entrenada anteriormente utilizando gradiente descendente con algun _learn rate_ que les parezca adecuado luego de la exploración en la pregunta anterior. \n",
    "\n",
    "* En caso de elegir explorar distintas funciones de activación, cambie la activación de la capa oculta sucesivamente por: tangente hiperbólica, _Leaky ReLu_, _softmax_, sigmoidea y lineal. Para esto puede basarse en el código presentado abajo y la documentación de keras. Para la activación _Leaky ReLu_ pruebe cambiar el parámetro de la red. Describa sus resultados y si observa diferencias entre las redes. \n",
    "\n",
    "* En caso de elegir explorar las funciones de regularización usual, agregue regularización $l$1 o $l$2 a la capa oculta y pruebe cambiar la tasa de regularización, reportando sus resultados. ¿Qué ocurre si la regularización es muy alta o muy baja? Una vez satisfecho con una tasa de regularización, aplique la regularización a la capa de salida y luego a ambas capas. \n",
    "\n",
    "**Independiente de la opción elegida**, comente sobre los siguientes temas:\n",
    "\n",
    "¿Cual es el interez de tener activaciones no lineales? ¿Le parece buena opción la activación sigmoidea para la capa oculta? ¿Qué pasaría si usaramos esta activación en la capa de salida? \n",
    "\n",
    "¿Cual es la intención de la regularización en general? En particular, ¿Que restricción implicita imponen las regularizaciones $l$1 o $l$2 sobre los pesos de la capa en la cual se aplican? Apoyese de ecuaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activations\n",
    "from keras.layers import LeakyReLU\n",
    "model.add(Dense( # . . . ))\n",
    "model.add(LeakyReLU())\n",
    "    \n",
    "# regularizer\n",
    "from keras.regularizers import l1, l2\n",
    "model.add(\n",
    "    Dense( # . . .\n",
    "          activity_regularizer=l2(0.001)\n",
    "         )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.g Exploración del Número de neuronas\n",
    "\n",
    "Ahora probaremos cambiando el número de neuronas en la capa oculta. Para esto, entrenen la red que estimen conveniente luego de la pregunta anterior, variando el numero de nuronas. Deben explorar a lo menos 10 número de neuronas distintos. Una recomendación sería por ejemplo explorar numero de neuronas en potencias de 2. \n",
    "\n",
    "Para cada red entrenada, recuperen el mejor error de validación y el error de entrenamiento en la _epoch_ donde se obtuvo tal error de validación. Grafique como se comportan ambos errores a medida crece el número de neuronas y comente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_error, val_error = [], []\n",
    "\n",
    "for n_units in # . . . \n",
    "    \n",
    "    # do model \n",
    "    \n",
    "    # train model \n",
    "    \n",
    "    val_error = min(history.history['val_loss'])\n",
    "    train_error = history.history['loss'][np.argmin(history.history['val_loss'])] \n",
    "    # for instance\n",
    "    \n",
    "# . . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.h Dropout\n",
    "Como seguramente constataron en la pregunta anterior, un numero demasiado grande de parámetros en el modelo puede llevarnos a observar el fenomeno de _overfitting_. Una aproximación a este fenómeno que ha dado excelente resultado en redes neuronales es el método _dropout_, donde estocásticamente se desactivan una fracción de las neuronas al momento del entrenamiento, así efectivamente reduciendo el tamaño del modelo que se entrena en cada iteración e implicitamente obteniendo modelos más robustos por el simple hecho que al momento de entrenar nunca se entrena el \"mismo\" modelo. \n",
    "\n",
    "Según lo aprendido en el ramo, ¿en qué consiste el fenómeno de _overfitting_? ¿Por qué modelos más grandes suelen presentar el fenómeno? \n",
    "\n",
    "Entrene la mejor red obtenida en la pregunta anterior agregando una capa de _Dropout_ con parámetro $0.5$ inmediatamente luego de la capa oculta. Repita luego el proceso con una red con el doble de neuronas. Note que el agregar una capa _dropout_ hará que la red entrene más lento, por lo cual es recomendable aumentar el numero de _epochs_ para entrenar la red a completitud. \n",
    "\n",
    "¿Qué observa al agregar _dropout_? Comente y compare con sus resultados anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# . . . \n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.i Extreme Learning Machine\n",
    "\n",
    "Otra aproximación para obtener modelos grandes que no sobreajustan es la implementada por _ELM_. Explique en qué consiste la idea de _ELM_ y porqué esto podría evitar sobreajuste a pesar de utilizar modelos con gran número de parámetros. \n",
    "\n",
    "Entrene una _ELM_ de una capa fija y una capa oculta, la primera con un número relativamente grande y la segunda con un número relativamente pequeño. Puede utilizar los valores propuestos en el código u otros que le parezcan convenientes. \n",
    "\n",
    "Comente sobre el número total de parámetros y el número de parametros entrenables con respecto a los modelos anteriores. ¿Cómo se desempeña la red? ¿El número elevado de parámetros totales implica necesariamente _overfitting_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . . \n",
    "\n",
    "model.add(\n",
    "    Dense(units=5000,\n",
    "          activation=relu,\n",
    "         )\n",
    ")\n",
    "\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "# . . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.j Learning Rate Decay\n",
    "Ahora entrenaremos un modelo manejando manualmente el _learn rate_. Para esto utilizaremos el _callback_ `LearningRateScheduler`. Este _callback_ nos permitirá implementar una función que maneje el _learn rate_ de nuestro modelo. \n",
    "\n",
    "Escriba una función que reciba la epoca actual y retorne un _learn rate_ lr. El lr inicial debe ser igual o mayor a alguno que haya dado buenos resultados en las preguntas anteriores. La función debe dividir por 2 el lr cada 10 _epochs_. Además ponga como restricción que el lr no debe ser menor a $5\\times 10^{-5}$, es decir si el valor obtenido es menor a  $5\\times 10^{-5}$, la función retorna  $5\\times 10^{-5}$.\n",
    "\n",
    "Entrene su red preferida de las preguntas anteriores con esta modificación, grafique los errores a lo largo del entrenamiento y comente. Según lo visto en el ramo, ¿por qué podría ser util disminuir el _learn rate_ a medida se avanza en el aprendizaje de la red?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def step_decay(epoch):\n",
    "    \n",
    "    \n",
    "    return lr\n",
    "\n",
    "schedule = LearningRateScheduler(step_decay)\n",
    "\n",
    "# model. # . . . \n",
    "\n",
    "model.fit(# . . .\n",
    "        callbacks=[schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.k Vanishing Gradient\n",
    "\n",
    "El fenómeno del _vanishing gradient_ es el rápido decaimiento del paso de _Backpropagation_ al avanzar por las capas. A lo largo de la tarea solo hemos entrenado capas con una red oculta, de igual forma que la comunidad cientifica realizo por largo tiempo, por el problema del _vanishing gradient_ y por el teorema de aproximación universal que resumidamente demuestra que una red de una sola capa puede aproximar una amplia familia de funciones. \n",
    "\n",
    "En esta pregunta entrenaremos una red neuronal profunda sin implementar ninguno de los dispositivos que permiten hoy en día sortear el problema del _vanishing gradient_, para ponerlo en evidencia. Para esto construya una red con 6 capas ocultas, con la siguiente lista de numero de neuronas: $256$ $256$ $128$ $128$ $32$ y $32$, o con valores similares. De tal manera obtendrá un valor de parámetros relativamente comparable a los valores utilizados en las primeras redes. \n",
    "\n",
    "Grafique un histograma con los pesos de las 6 capas densas de la red sin entrenar, entrenela a completitud con el método que estime conveniente y luego grafique nuevamente los histogramas para las 6 capas. Comente lo que observa. \n",
    "\n",
    "Luego, pruebe cambiar la inizialización de los pesos de la capa densa, puede revisar la documentación de keras para ver las opciones existentes a parte de `glorot_uniform` por defecto. ¿Se logra solucionar el problema? \n",
    "\n",
    "Por último, pruebe aumentar la tasa de aprendizaje para ver si logra hacer que el paso de _backpropagation_ alcance las capas que anteriormente no se entrenaban. ¿Qué observa en este caso? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . .\n",
    "\n",
    "layer_kernel_weights = model.get_layer(index=i).get_weights()[0]\n",
    "layer_bias_weight = model.get_layer(index=i).get_weights()[1]\n",
    "# for one layer\n",
    "# you can also name your layers and call them by their names if it's less confusing\n",
    "\n",
    "# . . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.l Otros Optimizadores\n",
    "\n",
    "Finalmente, utilizando la estructura de red que mejor se haya desempeñado a lo largo de la tarea, entrene esta red utilizando un optimizador distinto al gradiente descendente vainilla. Pruebe al menos 2 optimizadores implementados en keras (puede utilizar Adam, AdaGrad, AdaDelta, RMSprop, entre otros) o modificar los parámetros que no hemos utilizado del gradiente descendente (momentum, momentum de Nesterov...).\n",
    "\n",
    "Note que por las inicializaciones por defecto de los pesos de las capas y la naturaleza de los datos en cuestión, puede ocurrir que para los valores defecto de algunos optimizadores la red diverga en las primeras iteraciones. Para fijar los parámeros de los optimizadores debe importarlos desde `keras.optimizers` y pasar el objeto con los parámetros deseados al método `.compile` de su modelo. En cambio si con los valores usuales basta, algunos optimizadores pueden pasarse como `string` a `.compile`.\n",
    "\n",
    "Compare como se desempeñan estos optimizadores con la versión utilizada anteriormente, considerando los tiempos de entrenamiento, la velocidad de convergencia y el desempeño final alcanzado. Apoyese de gráficos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.m Testing \n",
    "\n",
    "Finalmente, luego de entrenar todos estos modelos estamos en condiciones de probar que tan bien fue nuestro desempeño. Para esto utilice el modelo en el cual obtuvo el mejor desempeño en validación y calcule el error cuadrático medio de la predicción realizada sobre el _Test set_. Para puede utilizar el metodo `.predict` de su modelo. \n",
    "\n",
    "¿Qué tan bien se desempeñaría su modelo en un caso real en vista de lo anterior? Si su curiosidad es suficiente, puede calcular el error real de su modelo transformando nuevamente el _target_ y su predicción a la escala original (utilizando su `scaler`) y tranformando a precio aplicando exponenciación (pues Y estaba espresado en escala logaritmica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Reconocimiento de Imagenes en CIFAR10\n",
    "\n",
    "Una de las areas donde las redes neuronales han obtenido desempeños decisivamente superiores al resto de los métodos existentes en su momento es en el reconocimiento de imagenes. La capacidad de las redes convolucionaes de aprender y extraer patrones sobre patrones hasta obtener caracteristicas de alto nivel representativas de atributos buscados en las imaganes ha permitido en desempeños superiores a los obtenidos por otros métodos de aprendizaje automatico o inteligencia aritificial, e incluso en algunos casos a el desempeño humano. \n",
    "\n",
    "Una de las tareas usuales que se pueden resolver con redes neuronales convolucionales es la clasificación de imágenes. Uno de los _datasets_ más extendidos en la literatura para esta terea es el CIFAR10, el cual se compone de 50000 imagenes de entrenamiento de 10 clases distintas. El _dataset_ tiene un tamaño suficiente para lograr entrenar redes relativamente grandes y permite una buena introducción a este ampio campo, sobretodo por su facilidad de utilización y preprocesamiento prácticamente nulo. Durante esta pregunta utilizaremos este _dataset_ para explorar los conceptos básicos de redes convolucionales y algunas luces de problemas de clasificación. \n",
    "\n",
    "Note que el entrenamiento de redes convolucionales se beneficia particularmente del uso de unidades de procesamiento gráfico, por lo cual podría ser recomendable utilizarlas en caso de disponer, o considerar correr los codigos completos una vez verificado su funcionamiento en una sesión de Collab acelerada por GPU, entre otras opciones de GPU en la nube existentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a Carga de datos y visualizaciones\n",
    "Cargue los datos como muestra el código siguiente. Como pueden ver el dataset es tan utilizado que funciones para cargarlo vienen implementadas en keras. \n",
    "\n",
    "Luego, visualice algunas imagenes de cada una de las catégorias junto con sus nombres (puede encontrar los nombres de las categorías en el siguiente link https://www.cs.toronto.edu/~kriz/cifar.html). ¿Qué pares de categorías cree podrían ocasionar problemas al momento de clasificación? ¿Qué tan bien cree que se desempeñaría un humano en esta tarea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_tr,y_tr),(x_val,y_val) = cifar10.load_data()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(# . . .)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Ligero preprocesamiento\n",
    "\n",
    "Este _dataset_ viene tan bien preprocesado, con las clases balanceadas, el set de validación a parte y todas las imagenes de la misma dimensión que no será necesario gran preprocesamiento. Simplementen transformaremos la escala de las imagenes, de $[0,255]$ a $[-1,1]$. Para esto simplemente se puede realizar las operaciones aritmeticas que \n",
    "muestran en el código.\n",
    "\n",
    "¿Perdemos información con este preprocesamiento? ¿Qué representa cada uno de los valores de la tupla `x_tr.shape`? \n",
    "\n",
    "¿Podemos considerar los valores de $y$ como valores numéricos o debemos transformarlos de alguna forma? \n",
    "\n",
    "Utilice la función `to_categorical` de keras para transformar $y$ a _encodding_ _one hot vector_. ¿Cómo se transformo el `.shape` de $y$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_tr/127.5 - 1\n",
    "\n",
    "# . . . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c Primera red Convolucional\n",
    "\n",
    "Entrenaremos una primera red convolucional sobre los datos, con la mayoría de los parámetros por defecto. Cree primero la red siguiendo la estructura $C\\times P\\times C\\times P \\times D$ donde $C$ representa una capa convolucional, $P$ una capa de _Max pooling_ y $D$ una capa densa. Note que antes de la capa densa debe agregar una capa _Flatten_ que transforma los filtros a vectores que luego pueden ser utilizados por la capa densa. \n",
    "\n",
    "Para los parámetros de las capas, fijaremos ambas capas convolucionales con 128 filtros de $3\\times 3$ sin _stride_ y _padding 'same'_ (es decir agregaremos 0 a los bordes de la imagen de tal manera que se preserve la dimiensión de la imagen al atravesar la capa; y las capas de _pooling_ tendrán tamaño y _stride_ $2\\times 2$, como muestra el código. Note que al igual que en la pregunta 1, el modelo en este caso es `Sequential`, pues los valores de una capa se pasan secuencialmente a la siguiente. \n",
    "\n",
    "Utilice el método `.summary` del modelo para ver la cantidad de parámetros y las dimensiones de los outputs de cada capa (note que como en la primera capa especificamos el `input_shape` podemos llamar el método antes de compilar el modelo o de pasarle datos. Justifique el número parámetros y el _Output Shape_ de cada capa en función de la estructura de la red y lo aprendido en clases. \n",
    "\n",
    "¿Por qué la capa de salida debe tener 10 neuronas? ¿Qué operación efectua la activación _SoftMax_? ¿Qué representaría en terminos del problema el vector de salida de la red?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# . . .\n",
    "\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size=(2, 2),\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=x_tr.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# . . . \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(# . . . ))\n",
    "    \n",
    "model.add(Dense(units=10, activation='softmax')) # output\n",
    "\n",
    "    \n",
    "# summary\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d Primer entrenamiento\n",
    "\n",
    "Compile la red definida en el item anterior. Para esta pregunta puede usar los optimizadores configurados por defecto, y debe usar como _loss_ _Categorical Crossentropy_. ¿Por qué preferimos medir _crossentropy_ y no por ejemplo _MSE_ en este problema? Mida igualmente el _accuracy_ como se muestra en el código. \n",
    "\n",
    "Entrene la red hasta observar convergencia (al rededor de 20 _epochs_ usualmente) recuperando su `history`. Grafique como varia el _accuracy_ en entrenamiento y validación a lo largo del aprendizaje. ¿Qué valor representa el _accuracy_? ¿Le parece buena medida de desempeño para este problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# fit. Don't forget to add validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.e Bloque $C\\times C\\times P$\n",
    "\n",
    "Una practica usual en redes convolucionales es apilar más de un filtro convolucional antes de aplicar _pooling_. La idea detras de esto es darle mas \"espacio\" a la red para aprender los patrones relevantes antes de realizar el subsampleo mediante el _pooling_. En el caso de este _dataset_ también nos permite agregar más capas convolucionales sin reducir tan fuertemente la dimensión de las imagenes filtradas. Incluso muchos investigadores optan por agregar más de una capa densa el final de la red, para dar aún más libertad al modelo, pues las restricciones impuestas sobre los parámetros por la estructura convolucional parecieran restringir lo suficiente al modelo y más libertad en las capas finales no pareciera implicar un _overfitting_ tan fuerte como sería por ejemplo en una red _Fully Connected_.\n",
    "\n",
    "Cree y entrene una red, utilizando dos bloques de dos capas convolucionales y una de _maxpool_ y luego dos capas densas, es decir $C\\times C\\times P \\times C\\times C\\times P\\times D \\times D$. Utilice $128$ filtros $3\\times 3$ en las dos primeras convolucionales y $64$ filtros $3\\times 3$ en las dos siguientes. Ambas capas de _maxpool_ utilice tamaño y _stride_ $2\\times 2$. \n",
    "\n",
    "Comente como se compara el desempeño con las redes anteriores. Apoyese de gráficos y valores numéricos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.f Exploración de profundidad\n",
    "\n",
    "Por comodidad preferiremos quedarnos con la estructura en bloques del item anterior. En esta pregunta deberan explorar que ocurre a medida uno cambia la profundidad de la red. Para esto, entrene redes con distinto numero de bloques. Debe a lo menos entrenar una red por cada numero de bloques entre 1 y 5 bloques (¿qué particularidad tiene la red con 5 bloques? ¿Puede entrenar una más profunda?). También si lo desea puede entrenar una red con \"0\" bloques, es decir una red densa como las de la pregunta 1. \n",
    "\n",
    "Comente sobre los casos extremos (0 bloques y 5 bloques), ya sea a partir de lo aprendido en clases o lo que observa al momento de entrenar las redes. ¿Le parece alguno de los dós sea buena aproximación para reconocimiento de imagenes? Para cada red recupere `history` y grafique el valor del mejor _accuracy_ en validación y el _accuracy_ sobre entrenamiento en el mismo _epoch_ en función de la profundidad de la red, similar al procedimiento realizado en 1.g.\n",
    "\n",
    "Queda a su discreción los parámetros de cada capa convolucional, pueden utilizar el número de filtros que estimen convenientes, solo no utilicen _stride_, y en caso de utilizar alguna regla para el número de filtros, que tal regla sea la misma para todas las profundidades (pueden ver dos posibles ejemplos en el código propuesto abajo). Para las capas de _MaxPool_ utilicen las que aparecen en el código.\n",
    "\n",
    "Para ahorrar tiempo, si observa que una red no converge, puede detener anticipadamente el entrenamiento. Para esto es recomendable usar el _Callback_ de keras `EarlyStopping` el cual deben agregar al momento de utilizar el método `.fit` (ejemplo similar en 1.e), sin embargo asegurese de ponerle _patience_ de a lo menos 3, pues como podrá observar algunas redes empeoran su desempeño en algunas _epochs_ para luego seguir mejorando. Puede elegir monitorear la métrica que estime conveniente para esta pregunta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for block_num # . . . \n",
    "\n",
    "    # create model\n",
    "\n",
    "    for i in range(block_num):\n",
    "        \n",
    "        model.add(Conv2D(128, (3,3),padding='same',activation='relu'))\n",
    "        model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        # or for instance\n",
    "        \n",
    "        model.add(Conv2D(int(128/(i+2)), (3,3),padding='same',activation='relu'))\n",
    "        model.add(Conv2D(int(128/(i+2)), (3,3), padding='same', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "    # flatten\n",
    "    # dense's\n",
    "    # compile\n",
    "    # train and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.g Exploración libre\n",
    "\n",
    "Como probablemente ya habrán notado, la cantidad de hiperparámetros que se pueden fijar y explorar en una red convolucional es enorme. A parte de poder modificar la arquitectura de la red y su tamaño o profundidad, pueden en cada una de las capas modificar el número de filtros, el tamaño de los filtros; agregar _stride_, cambiar las activaciones, cambiar el _padding_, cambiar los tamaños de los _MaxPool_ o sus _strides_ o incluso modificar las capas densas al final de la red. \n",
    "\n",
    "Por motivos de tiempo y con la esperanza de que la tarea no sea más tediosa de lo necesario, en vez de pedir explorar cada uno de estos parámetros, se les propone elegir una exploración de la siguiente lista. Debe realizar la exploración exahustivamente, comentar sus resultados apoyandose de gráficos y su conocimiento teórico cuando sea apropiado. Independiente de la exploración elegida debe responder las preguntas finales. \n",
    "\n",
    "Para todas las exploraciones utilice como _template_ la mejor red entrenada hasta ahora y modifique el parámetro relevante. Si utiliza otra red, justifique brévemente su elección. \n",
    "\n",
    "**Exploraciones posibles (Elija 1)**\n",
    "* Tamaño de los filtros: Manteniendo el filtro cuadrado, explore cambiar el tamaño de filtro de alguna(s) capas convolucionales. Debe explorar a lo menos valores de $1\\times 1$ hasta $9\\times 9$, por lo cual debe asegurarse realizar la exploración en una capa donde las dimensiones de los filtros de la capa anterior (o el Input de la capa) se lo permita. \n",
    "* Exploración del número de filtros: Explore variando el número de filtros de alguna(s) capas. Se recomienda explorar en potencias de 2, y debe explorar a lo menos 10 valores distintos.\n",
    "* Neuronas capa Densa: realice una exploración del número de neuronas de alguna o ambas de las capas densas. Debe explorar a lo menos 10 combinaciones distintas. Puede dejar una de las dos capas fijas y variar la otra siguiendo potencias de 2 por ejemplo. Tenga cuidado con la explosión del número de parámetros. \n",
    "* Pooling: Pruebe cambiar el tamaño de los _MaxPool_ entre $2\\times 2$ a $6\\times 6$. Pruebe también cambiando todas las capas por `AveragePooling2D`, realizando la misma exploración que con _MaxPool_.\n",
    "* Pooling \"convolucional\": Una aproximación posible para reemplazar las capas de _maxpool_ es utilizando capas convolucionales con kernel $2\\times 2$ y _stride_ $2\\times 2$. Pruebe reemplazando las capas _maxpool_ por este tipo de capas, luego pruebe una mezcla de ambas, luego pruebe simplemente eliminando las capas de _pooling_ y agregandole _stride_ a la segunda capa de cada bloque (con _kernel size_ $2\\times 2$ y $3 \\times 3$). Pruebe finalmente cambiando las funciones de activación de las capas donde se realiza la disminución de dimensión, probando a lo menos activación lineal, sigmoidea y tangente hiperbólica.\n",
    "\n",
    "**Preguntas (respondalas todas)**:\n",
    "* ¿A que equivaldría utilizar tamaño de kernel $1 \\times 1$?\n",
    "* ¿Por qué si cambiamos el número de filtros de una capa también modificamos el número de parámetros de la siguiente capa?\n",
    "* ¿En su opinión, qué metodo resumen mejor la información de una capa, _maxpool_ o _averagepool_'\n",
    "* ¿Que tipo de patrones esperaría usted que se extraigan mejor con un kernel no cuadrado (por ejemplo $3\\times 2$)? Apoyese de un ejemplo pequeño o una explique el fenómeno llevandolo al \"extremo\" (e.g. $1\\times 3$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.h Dropout\n",
    "Como vimos en la pregunta 1, _dropout_ es una técnica de regularización muy util para evitar overfitting. En el caso de convolucionales, aplicaremos _dropout_ en las capas densas al final. ¿Cree que es una buena idea aplicar _dropout_ en las capas convolucionales? ¿Por qué?\n",
    "\n",
    "Entrene la mejor red que ha entrenado hasta ahora, agregando _dropout_ en a lo menos una de las capas densas. Donde aplique _dropout_ aumente el número de neuronas. Utilice parámetro 0.5. Reporte sus resultados apoyandose de gráficos. Recuerde que las redes con _dropout_ toman más tiempo en entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# . . . \n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.i Data Augmentation\n",
    "\n",
    "Otra manera de evitar sobreajuste y mejorar los desempeños de una red convolucionar es usar aumentación de datos. La idea detras de este método es un hecho muy simple: si rotamos ligeramente una foto por ejemplo de un caballo, seguirá siendo de un caballo. Lo mismo si la movemos ligeramente hacia algun lado, hacia arriba, _etc_.\n",
    "\n",
    "Keras trae implementado un generador de imagenes aumentadas, puede basarse en el código abajo para utilizarlo, aunque si lo desea o estima conveniente puede cambiar alguno de los parametros. Entrene a completitud la mejor red que obtuvo a lo largo de toda la tarea. ¿Qué tanto mejora el desempeño de la red utilizando aumentación de datos? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.1,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='constant',\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None)\n",
    "\n",
    "datagen.fit(x_tr)\n",
    "\n",
    "# . . . \n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_tr, y_tr, batch_size=32),\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    validation_freq=1,\n",
    "                    shuffle=True)\n",
    "\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.j Matriz de Confusión\n",
    "\n",
    "Si bien el _accuracy_ nos ha acompañado toda la pregunta para evaluar el desempeño de nuestras redes de forma fácilmente interpretable, no considera por ejemplo si una gran parte de los errores provienen de una sola clase, o si alguna clase se logra clasificar perfectamente. Una manera de visualizar fácilmente esta métrica más granular, es utilizando la matriz de confusión. Investigue y explique brévemente en qué consiste una matriz de confusión (puede explicar el caso binario donde solo hay dos clases).\n",
    "\n",
    "Luego, apoyándose en los códigos de abajo, visualizaremos la matriz de confusión del modelo que mejor se desempeñó a lo largo de toda la tarea. \n",
    "\n",
    "- ¿Algo le llama la atención? \n",
    "- ¿Qué clases se confunden más entre si?\n",
    "- ¿Coincidió esto con sus predicciones al inicio de la tarea? \n",
    "\n",
    "Igual de la misma forma que en 2.a, visualice algunas imagenes mal clasificadas por su modelo. \n",
    "- ¿Le parece razonable que el modelo no las clasifique bien?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Puede usar libreria seaborn para realizar facilmente heatmaps anotados: \n",
    "import seaborn as sns\n",
    "# . . .\n",
    "sns.heatmap( confusion_matrix(y_val # . . . ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.k Visualizaciones\n",
    "\n",
    "Ahora, si bien vemos que nuestras redes se han comportado relativamente bien en esta tarea, no podríamos decir exactamente por qué. Una forma de acercarnos a entende aproximadamente que está haciendo la red es visualizando los pesos y viendo como se transforma una imagen a medida pasa por la red. \n",
    "\n",
    "Utilizando su red de mejor desempeño, represente gráficamente los pesos de las distintas capas, a lo menos de la primera y la última capa convolucional. Recuerde que puede obtener los pesos de una capa como se presenta en el item 1.k, teniendo atención que en este caso los pesos se presentarán como un array de los kernels.\n",
    "\n",
    "Luego, de alguna clase elija unas imagenes al azar y grafíque los filtros que la red extrae a partir de la imagen a lo largo que esta pasa por las capas. Puede utilizar la función propuesta abajo para obtener el modelo truncado, luego con `.predict` obtendrá la imagen filtrada que busca. Nuevamente ponga énfasis en la primera y ultima capa. Elija otra clase y repita el proceso. Comente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_layers(max_layer, original_model):\n",
    "    truncated_model = Sequential()\n",
    "    for layer in range(max_layer):\n",
    "        truncated_model.add(original_model.get_layer(index=lay))\n",
    "    return truncated_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Reconocimiento de frutas y verduras\n",
    "\n",
    "Si bien CIFAR10 es una buenisima herramienta para introducirse a las redes neuronales convolucionales, sin embargo varias características de CIFAR10 lo hacen estar un poco alejado de la realidad del reconocimiento de imagenes hoy en día. Por ejemplo, como pudieron notar en la pregunta anterior, la resolución de $32\\times 32$ es a penas suficiente para reconocer el objeto. Además 10 clases es relativamente poco comparado con los modelos del estado del arte, que obtienen resultado decentes en problemas con miles de categorías. Otra cosa que podrían haber notado, es que las redes entrenadas no tenían mucho problema en diferenciar clases \"más\" distintas que otras (por ejemplo, que cree que hubiera pasado si hubieramos truncado el _dataset_ para solo contener la clase caballo y avión, ¿cree que los desempeños serían los mismos?), mientras que en categorías más \"cercanas\" (como perro, gato y caballo) los desempeños eran relativamente peores. Es por esto que muchos _datasets_ utilizados en el estado del arte incluyen no solo variedad entre sus categorías, si no tambien categorías similares, que podrían agruparse en categorías de mayor gerarquía incluso. \n",
    "\n",
    "En esta pregunta, intentaremos de realizar un analisis sobre un _dataset_ un poco más realista, donde encontrará algunos de los problemas asociados a trabajar con gran número de imagenes. Originalmente se consideró trabajar con uno de los _dataset_ usuales en el estado del arte, el Caltech256, sin embargo por motivos de tiempo se prefirió este _dataset_ donde las imagenes vienen todas en el mismo formato ($100\\times 100$) y no tendrémos que realizar preprocesamiento más acabados como aquellos que necesitaríamos con Caltech. El _dataset_ en cuestión corresponde a un problema de reconocimiento de frutas y verduras, disponible en el siguiente link de _kaggle_ https://www.kaggle.com/moltean/fruits o en el siguiente repositorio https://github.com/Horea94/Fruit-Images-Dataset. Este _dataset_ contiene miles de imagenes de 120 frutas y verduras diferentes clasificadas por variedades. Intentaremos resolver este problema utilizando las 120 clases, notando que si bien el hecho de acortarse a un campo semantico en particular (i.e. frutas y verduras) permitirá que nuestro algoritmo se especialice más en la detección de las diferencias entre sus categorías, también implica que las diferencias seran más pequeñas que lo que serían en un _dataset_ más variado. Luego intentaremos resolver el problema utilizando categorías más amplias, donde no se distinga entre variedades de la misma fruta, y veremos en qué tarea tenemos mejor desempeño. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a Carga y preprocesamiento de Imagenes\n",
    "\n",
    "Lea la descripción del dataset para familiarizarse con la estructura donde se guardan las imagenes y como deberemos cargarlas recordando la categoría de cada una. \n",
    "\n",
    "Cargue todas las imagenes junto con sus categorías a un _DataFrame_. Note que esto puede tomar bastante tiempo por la cantidad de imagenes. El código propuesto utiliza la librería Pillow, sin embargo pueden usar el método que prefieran, incluso pueden no basarse para nada en el código propuesto. Aprovecharemos la separación de _Training_ y _Test_ de _dataset_, y utilizaremos el primero para entrenamiento y el segundo para validación. \n",
    "\n",
    "Esta vez optaremos por dejar los valores entre $[-127, 128]$ para poder utilizar un encoding `uint8` en `numpy` lo cual reducirá drásticamente el uso de memoria al momento de cargar los datos. Separe luego los arrays de inputs y outputs de nuestro modelo, sin olvidar transformar las categorías del _target_ a _one hot vector_ como aprendió en el resto de la tarea. \n",
    "\n",
    "Si lo desea, podría ser recomendable guardar los datos preprocesados utiizando la función `np.save` para ahorrarse el tiempo de computo que requiere esta operación en caso de que tuviera que correr varias veces esta pregunta. \n",
    "\n",
    "Visualice alguna de las imagenes en `image_list`. Verifique que los datos se hayan cargado bien viendo los `shape` de los arrays o con algun otro indicador que le dé algo de confianza. Utilice `matplotlib.pyplot.imshow` con algunos ejemplos de los _arrays_ para verificar que no se haya perdido información y que la carga de datos se realizó correctamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "# . . .\n",
    "# note that the folders have been modified from the original, you have to modify them to coincide with yours\n",
    "base_path = os.getcwd()\n",
    "data_path = os.path.join(base_path, \"data\", \"fruits\",train_or_test) \n",
    "categories = os.listdir(data_path)\n",
    "\n",
    "image_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['x','y'])\n",
    "for cat in categories:\n",
    "    image_files = os.listdir(os.path.join(data_path, cat))\n",
    "    for image_path in image_files:\n",
    "        if '.jpg' in image_path: # to avoid unpleseant surprises\n",
    "            full_path = os.path.join(data_path, cat, image_path)\n",
    "            im = PIL.Image.open(full_path)\n",
    "            arr = np.asarray(im)\n",
    "            df = df.append({'x':arr, 'y':cat}, ignore_index=True)\n",
    "    image_list.append(im)\n",
    "    \n",
    "# . . .\n",
    "# . . . \n",
    "# you may need np.concatenate when defining x_tr in order not to have an array of arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Primera red\n",
    "Entrene una primera red que alcance un _accuracy_ sobre validación de a lo menos un $80\\%$\n",
    "\n",
    "Puede utilizar todos los conceptos aprendidos en la tarea anterior, aunque la recomendación es dejar _Data Augmentation_ para una última iteración, una vez ya hayamos encontrado una estructura que se comporte relativamente bien. Una arquitectura relativamente buena podria ser una basada en los bloques definidos en el item 2.e, con al rededor de 5 bloques. Si desea aumentar la profundidad de su red sientase libre utilizar otras estructuras con menos _MaxPool_. Note que la nueva base de datos permite crear redes más profundas de todas  formas, pues no se alcanza el limite impuesto por la dimensión de las imagenes tan pronto. \n",
    "\n",
    "Reporte el resultado de un par de redes, comentando por qué realizo ajustes a ellas. Note que estos entrenamiento implican calculos con grandes cantidades de datos y probablemente sea recomendarlo correrlos en _hardware_ acelerado por GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c Batch Normalization\n",
    "Una manera propuesta de mejorar los desempeños de las redes en general, que funciona bastante bien en tareas de reconocimiento de imagenes es _Batch Normalization_. Segun su conocimiento teórico y investigación, ¿Qué realiza _Batch Normalization_ en términos matemáticos? En terminos de aprendizaje, ¿qué evita la utilización de _Batch Normalization_?\n",
    "\n",
    "Entren nuevamente su red preferida de la pregunta anterior, agregando capas de _Batch Normalization_ luego de cada capa de _MaxPool_. Comente sus resultados. \n",
    "\n",
    "¿Mejoran los desempeños de la red agregando _Batch Normalization_? ¿Existe diferencias entre una capa de _batch normalization_ justo antes o justo despues de una capa de _MaxPool_ en términos numéricos? ¿Opina lo mismo en términos de aprendizaje? Discuta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d Skip Connections\n",
    "Otra manera de mejorar los resultados de las redes, sobretodo de las redes profundas donde se observa el problema de _vanishing gradient_ son las relativamente nuevas _skip connections_ o redes residuales. En vez de preocuparse de como manejar los pesos de la red para permitir que el gradiente no explote o no desaparezca, se permite al gradiente \"pasar\" sin ser modificado, agregando conecciones con pesos fijos entre capas de distintas profundidades, en la practica permitiendo a la señar \"saltarse\" las capas intermedias. Esta idea ha permitido desarrollos como los de ResNet, llegando a profundidades de cientos de capas y aún logrando aprendizaje. \n",
    "\n",
    "Para implementar estas ideas debemos utilizar la API funcional de Keras al momento de construir los modelos. Algo que debemos notar es que la mayoría de los objetos de keras pueden ser llamados como funciones, y al momento de hacerlo con objetos `layers` es equivalente a conectarlos, por lo cual si hacemos `x(y)` retornamos un objeto con la capa `y` conectada a la capa `x`. \n",
    "\n",
    "Basandose en el código mostrado abajo, implemente una ResNet de su gusto, puede agregar _Skip conections_ a una red utilizada anteriormente o crear una nueva. Con estas redes debería lograr facilmente un _accuracy_ de al menos $90\\%$\n",
    "\n",
    "Comente sus resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(x_tr.shape[1:])\n",
    "\n",
    "y = Conv2D(64, (3,3),padding='same',activation='relu')(x)\n",
    "y = Conv2D(64, (3,3),padding='same',activation='relu')(y)\n",
    "\n",
    "z = concatenate([x, y])\n",
    "\n",
    "z = MaxPooling2D(pool_size=(2, 2))(z)\n",
    "\n",
    "y = Conv2D(64, (3,3),padding='same',activation='relu')(z)\n",
    "y = Conv2D(64, (3,3),padding='same',activation='relu')(y)\n",
    "\n",
    "z = concatenate([z, y])\n",
    "\n",
    "# . . .\n",
    "\n",
    "\n",
    "# . . . \n",
    "\n",
    "\n",
    "out = Dense(120, activation='softmax')(z)\n",
    "\n",
    "res_mod = Model(inputs=x, output=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.e Red Final \n",
    "\n",
    "De todas las redes entrenadas anteriormente, elija la con mejor desempeño y entrenela utizando aumentación de datos como aprendió en las preguntas anteriores. ¿Mejora el desempeño de la red? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.f Modelo para frutas\n",
    "Repita la el item anterior, pero esta vez sobre el problema de clasificación de las frutas y verduras independiente de sus variedades. Para esto deberá cargar nuevamente los datos, esta vez transformando las categorías que originalmente eran un `string` a la primera palabra del string. Así al momento de hacer el paso a categorías y _one hot vector_, todas las imagenes con la misma fruta o verdura quedarán en la misma categoría. \n",
    "\n",
    "- ¿Cómo se desempeña el modelo esta vez? \n",
    "- ¿_A priori_ cuál habría considerado el problema más dificil para un modelo de aprendizaje de máquinas? Discuta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
